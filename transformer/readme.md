## Implementation of Transformer.

This is an implementation of Transformer. 

I have not applied it to any real tasks yet. Thus, this model is only used for understanding Transformer's workflow.



If you would want to learn more about the principles of Transformer, welcome to visit my blog for the detailed explanation:

[Understanding and implementing Transformer from scratch](https://houwenxin.github.io/posts/2020/01/blog-post-5/) .

I always hope I have made everything clear and correct, but if not, please let me know. 

Advice is welcome!



### Reference:

[1] Vaswani, A., et al. “Attention Is All You Need. arXiv 2017.” *arXiv preprint arXiv:1706.03762*.